{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9591a74-5b65-4340-8b1f-4e6d96e24a5f",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8f6a6d-f870-4dd1-8492-2ab4b5bafc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d317961-9e20-40d3-8ca6-ca4e3b6e5ef9",
   "metadata": {},
   "source": [
    "## Data Collection\r\n",
    "- Explain the Datalogger maybe or how the data was collect, number of cameras etc.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9f0d4f-ba32-4bdb-84c4-66010eddf4a3",
   "metadata": {},
   "source": [
    "## Network Architecture\n",
    "\n",
    "The network has 10 layers:\n",
    "1. A normalization layer to prepare the image data (implemented in the forward method).\n",
    "2. Five layers to identify features from the road images.\n",
    "3. Four layers to understand these features.\n",
    "4. Final output layer to make a deceision.\n",
    "\n",
    "The network processes images by converting them into YUV color space, normalizes them, and passes them through these layers to predict the steering angle.\n",
    "\n",
    "Reference: https://developer.nvidia.com/blog/deep-learning-self-driving-cars/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6fbb47-5a41-498e-84cf-3f7324c6633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfDrivingCarCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SelfDrivingCarCNN, self).__init__()\n",
    "        \n",
    "        # Normalization layer (not learned, implemented in forward pass)\n",
    "        \n",
    "        # Five Convolutional Layers(to identify features from images)\n",
    "        self.conv1 = nn.Conv2d(3, 24, kernel_size=5, stride=2)\n",
    "        self.conv2 = nn.Conv2d(24, 36, kernel_size=5, stride=2)\n",
    "        self.conv3 = nn.Conv2d(36, 48, kernel_size=5, stride=2)\n",
    "        self.conv4 = nn.Conv2d(48, 64, kernel_size=3, stride=1)\n",
    "        self.conv5 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "        \n",
    "        # Fully Connected Layers(to understand features and make decisions)\n",
    "        self.fc1 = nn.Linear(64*1*18, 1164)\n",
    "        self.fc2 = nn.Linear(1164, 100)\n",
    "        self.fc3 = nn.Linear(100, 50)\n",
    "        self.fc4 = nn.Linear(50, 10)\n",
    "        self.fc5 = nn.Linear(10, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Normalize the input image\n",
    "        x = (x / 255.0) - 0.5\n",
    "        \n",
    "        # Apply Convolutional Layers with ReLU activations(feature identification layers)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        \n",
    "        # Flatten the tensor(for decision-making layers)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Apply Fully Connected Layers with ReLU activations(the decision-making layers)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        \n",
    "        # Output layer\n",
    "        x = self.fc5(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = SelfDrivingCarCNN().to('cuda')\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f702adda-b070-485b-aae0-f187bf031aef",
   "metadata": {},
   "source": [
    "## Data Augmentation\r\n",
    "\r\n",
    "To help the car learn to recover from mistakes, we artificially shift and rotate the images during training. This teaches the car to handle various scenarios it might encounter on the road.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a867dcc-b4f5-43a1-902c-718c74a2e093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def augment_image(image, steering_angle):\n",
    "    tx = random.uniform(-20, 20)  # Random horizontal shift\n",
    "    ty = random.uniform(-10, 10)  # Random vertical shift\n",
    "    steering_angle += tx * 0.002  # Adjust steering angle based on horizontal shift\n",
    "\n",
    "    rows, cols, _ = image.shape\n",
    "    M = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "    image = cv2.warpAffine(image, M, (cols, rows))\n",
    "    \n",
    "    angle = random.uniform(-15, 15)  # Random rotation\n",
    "    M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)\n",
    "    image = cv2.warpAffine(image, M, (cols, rows))\n",
    "    \n",
    "    return image, steering_angle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b9566d-7d0d-47a7-9719-18f21bbee8b2",
   "metadata": {},
   "source": [
    "## Training Process\n",
    "\n",
    "1. **Data Preparation**: Load images and corresponding steering commands.\n",
    "2. **Data Augmentation**: Apply shifts and rotations to images.\n",
    "3. **Training**: Use the images to train the network to predict the steering commands.\n",
    "4. **Loss Calculation**: Calculate the difference between the predicted and actual steering commands using mean-squared error.\n",
    "5. **Backpropagation**: Adjust the network to minimize this error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c139f653-d74d-449d-a4a6-38b1388bb53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset class to load images and steering commands\n",
    "class DrivingDataset(Dataset):\n",
    "    def __init__(self, image_paths, steering_angles, transform=None, augment=False):\n",
    "        self.image_paths = image_paths\n",
    "        self.steering_angles = steering_angles\n",
    "        self.transform = transform\n",
    "        self.augment = augment\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        steering_angle = self.steering_angles[idx]\n",
    "        \n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, (200, 66))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n",
    "        \n",
    "        if self.augment:\n",
    "            image, steering_angle = augment_image(image, steering_angle)\n",
    "        \n",
    "        image = (image / 255.0) - 0.5\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        image = torch.from_numpy(image).float()\n",
    "        image = image.permute(2, 0, 1)\n",
    "        \n",
    "        return image, steering_angle\n",
    "\n",
    "# Sample call\n",
    "image_paths = ['path_to_image1.jpg', 'path_to_image2.jpg', ...]\n",
    "steering_angles = [0.0, 0.1, -0.1, ...]\n",
    "dataset = DrivingDataset(image_paths, steering_angles, augment=True)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Define the loss function (mean squared error) and optimizer (Adam)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, steering_angles in dataloader:\n",
    "        images = images.to('cuda')\n",
    "        steering_angles = steering_angles.to('cuda')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, steering_angles)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader)}')\n",
    "\n",
    "# Save the model to make predictions\n",
    "torch.save(model.state_dict(), 'model.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95803222-cf7f-4869-9b36-c86c9549e956",
   "metadata": {},
   "source": [
    "## Simulation and Evaluation\r\n",
    "\r\n",
    "Before testing the car on real roads, we evaluate its performance in a simulation. The simulator modifies images to see how the car would respond, and we measure its accuracy.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094965e4-736a-44c0-b8cc-3573d92bc39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model for evaluation\n",
    "model = SelfDrivingCarCNN()\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Function to preprocess a single image for prediction\n",
    "def preprocess_image(image_path):\n",
    "  \n",
    "    # Load and Resize the image to 66x200 pixels\n",
    "    image = cv2.imread(image_path)\n",
    "    resized_image = cv2.resize(image, (200, 66))\n",
    "    \n",
    "    # Convert the image to YUV color space\n",
    "    yuv_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2YUV)\n",
    "    \n",
    "    # Normalize the image\n",
    "    normalized_image = (yuv_image / 255.0) - 0.5\n",
    "    \n",
    "    # Convert to PyTorch tensor\n",
    "    input_image = torch.from_numpy(normalized_image).float()\n",
    "    \n",
    "    # Reorder dimensions to match PyTorch's expected input format: (batch_size, channels, height, width)\n",
    "    input_image = input_image.permute(2, 0, 1)  # Convert to (3, 66, 200)\n",
    "    \n",
    "    # Add batch dimension\n",
    "    input_image = input_image.unsqueeze(0)  # Convert to (1, 3, 66, 200)\n",
    "    \n",
    "    return input_image\n",
    "\n",
    "# Example prediction using preprocess_image\n",
    "image_path = 'path_to_image.jpg'\n",
    "input_image = preprocess_image(image_path).to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    steering_command = model(input_image)\n",
    "print(\"Predicted Steering Command:\", steering_command.item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
